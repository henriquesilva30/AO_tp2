{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# -*- coding: utf-8 -*-\n",
    " \n",
    "\n",
    "#Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Importar o Dataset\n",
    " \n",
    "dataset = pd.read_csv('Insol_3.csv',sep=';',header=0)\n",
    "\n",
    "X = dataset.drop('Insolvencia', axis=1)   #Colunas usadas para calcular a Insolvencia. ContÃªm as features\n",
    "y= dataset.Insolvencia                    #Parametro a ser calculado\n",
    "X.head\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-30T21:49:37.542384Z",
     "iopub.execute_input": "2022-05-30T21:49:37.543270Z",
     "iopub.status.idle": "2022-05-30T21:49:37.621743Z",
     "shell.execute_reply.started": "2022-05-30T21:49:37.543230Z",
     "shell.execute_reply": "2022-05-30T21:49:37.620837Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method NDFrame.head of       Distrito  NACE1  NACE2  Numero_Empregados  Num_anos_disponiveis_base  \\\n0            1     14    141                225                          9   \n1            1     13    139                 28                         10   \n2            5     14    141                 80                          9   \n3            5     14    141                175                          8   \n4            1     13    139                140                         10   \n...        ...    ...    ...                ...                        ...   \n2733         5     14    141                 35                          7   \n2734         5     14    141                  4                          4   \n2735         1     14    141                 11                          4   \n2736         1     13    139                 12                          9   \n2737         1     13    139                  4                          4   \n\n      Variacao_das_vendas  Variacao_resultado_operacional  Variacao_do_activo  \\\n0               -0.055116                      -12.183443           -0.081616   \n1               -0.163781                       -7.685481           -0.120590   \n2               -0.193743                       -1.486740           -0.118888   \n3               -0.156787                       -1.366234           -0.122807   \n4               -0.059913                       -0.742674           -0.019612   \n...                   ...                             ...                 ...   \n2733             0.027582                       -0.274997           -0.176842   \n2734            -0.404304                      -12.181545           -0.352600   \n2735             0.162294                        3.474090            0.034278   \n2736            -0.165809                        7.954233           -0.109300   \n2737            -0.402254                       -1.167466            0.095151   \n\n      Variacao_dos_capitais_proprios  Variacao_do_ativo_circulante  ...  \\\n0                          -0.353879                     -0.464741  ...   \n1                           0.002009                     -0.121442  ...   \n2                           0.055864                     -0.123646  ...   \n3                          -0.109388                     -0.127069  ...   \n4                           0.002116                     -0.041525  ...   \n...                              ...                           ...  ...   \n2733                       -0.062334                     -0.028360  ...   \n2734                       -3.845692                     -0.461129  ...   \n2735                        0.975000                      0.040681  ...   \n2736                        0.018465                     -0.108231  ...   \n2737                       -1.435204                      0.099516  ...   \n\n      Custos_dos_encargos_financeiros_dividir_resultado_operacional  \\\n0                                             -9.693646               \n1                                             -0.807625               \n2                                            -17.256303               \n3                                             -1.731467               \n4                                              4.747870               \n...                                                 ...               \n2733                                         -17.184075               \n2734                                          -6.629795               \n2735                                           1.652483               \n2736                                           0.614023               \n2737                                        -649.562500               \n\n      Rendibilidade_operacional_vendas  Rendibilidade_liquida_das_vendas  \\\n0                            -0.123985                         -0.139525   \n1                            -0.004936                          0.000886   \n2                            -0.015714                          0.007059   \n3                            -0.021469                         -0.059088   \n4                             0.046388                          0.054399   \n...                                ...                               ...   \n2733                         -0.067773                         -0.009809   \n2734                         -0.718577                         -0.825706   \n2735                          0.047219                          0.012692   \n2736                          0.072122                          0.004212   \n2737                         -1.082830                         -1.126380   \n\n      Rendibilidade_do_ativo  Rendibilidade_capitais_proprios  \\\n0                  -0.162146                        -0.353879   \n1                   0.001328                         0.002009   \n2                   0.028844                         0.055865   \n3                  -0.092117                        -0.109388   \n4                   0.033852                         0.038284   \n...                      ...                              ...   \n2733               -0.026195                         0.062334   \n2734               -1.067367                        -3.845692   \n2735                0.019160                        -0.975000   \n2736                0.003188                         0.018465   \n2737               -0.641165                         2.996812   \n\n      Passivo_curto_prazo_dividir_vendas  \\\n0                               0.904606   \n1                               0.103359   \n2                               0.100136   \n3                               0.422792   \n4                               0.223548   \n...                                  ...   \n2733                            0.901928   \n2734                            0.976505   \n2735                            0.684196   \n2736                            0.062618   \n2737                            1.286101   \n\n      Peso_das_amortizacoes_dividir_vendas  \\\n0                                 0.040788   \n1                                 0.025632   \n2                                 0.007319   \n3                                 0.016605   \n4                                 0.094521   \n...                                    ...   \n2733                              0.070954   \n2734                              0.060784   \n2735                              0.012913   \n2736                              0.003799   \n2737                              0.152428   \n\n      Peso_encargos_financeiros_dividir_vendas  Produtividade_por_trabalhador  \\\n0                                     0.012790                       0.905354   \n1                                     0.006112                       1.330416   \n2                                     0.000911                       1.205843   \n3                                     0.012399                       0.929479   \n4                                     0.009770                       1.774669   \n...                                        ...                            ...   \n2733                                  0.003944                       1.084723   \n2734                                  0.108386                       0.327668   \n2735                                  0.028575                       1.079392   \n2736                                  0.117459                       3.095021   \n2737                                  0.001667                       0.244005   \n\n      Certificacao_legal_contas  \n0                             1  \n1                             1  \n2                             1  \n3                             1  \n4                             1  \n...                         ...  \n2733                          0  \n2734                          0  \n2735                          0  \n2736                          0  \n2737                          0  \n\n[2738 rows x 32 columns]>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#Dividir em conjunto de treino e conjunto de teste\n",
    "import json\n",
    "jsonFile = open(\"data_split.json\", \"w\")\n",
    "jsonTxt = ''\n",
    "b= 0\n",
    "a = 0.10\n",
    "while b < 32:\n",
    "  b+=16\n",
    "  while a < 0.50:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=a, random_state=18)\n",
    "\n",
    "    #---------------------Cirar a Rede Neuronal Artificial--------------------------\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from numpy import loadtxt\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    #Adicionar a Input Layer e a primeira hidden layers\n",
    "    model.add(Dense(12, input_dim=32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    #Compiling the ANN\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',keras.metrics.Precision(),keras.metrics.Recall()])\n",
    "\n",
    "    #classifier.fit(X_train, y_train, batch_size = 10, epochs= 100)\n",
    "    model.fit(X_train, y_train, epochs=20, batch_size=10)\n",
    "    accuracy = model.evaluate(X, y, verbose=0)\n",
    "    data = {}\n",
    "    data['Test_size']='{:.2f}'.format(a)\n",
    "    data['Batch_size']=b\n",
    "    data['Loss_Acc_Prec_Recall']=accuracy\n",
    "#    jsonString = json.dumps(data,separators=('},',\",\"))\n",
    "    jsonString = json.dumps(data)\n",
    "    jsonTxt += jsonString+',\\n'\n",
    "    print('Test size {:.2f} + batch size {} = {}'.format(a,b,accuracy))\n",
    "    a +=0.05\n",
    "  a = 0.10\n",
    "jsonFile.write('['+jsonTxt+']')\n",
    "jsonFile.close()\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-30T21:51:17.316448Z",
     "iopub.execute_input": "2022-05-30T21:51:17.316903Z",
     "iopub.status.idle": "2022-05-30T21:52:05.629120Z",
     "shell.execute_reply.started": "2022-05-30T21:51:17.316869Z",
     "shell.execute_reply": "2022-05-30T21:52:05.628253Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "247/247 [==============================] - 2s 3ms/step - loss: 247.3010 - accuracy: 0.7394 - precision_128: 0.3599 - recall_128: 0.4086\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 300.8683 - accuracy: 0.7532 - precision_128: 0.4016 - recall_128: 0.5072\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 1s 2ms/step - loss: 237.3778 - accuracy: 0.7537 - precision_128: 0.3760 - recall_128: 0.3737\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 1s 3ms/step - loss: 344.3952 - accuracy: 0.7528 - precision_128: 0.3818 - recall_128: 0.4045\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 1s 2ms/step - loss: 242.2201 - accuracy: 0.7679 - precision_128: 0.4062 - recall_128: 0.3778\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 211.9888 - accuracy: 0.7589 - precision_128: 0.4110 - recall_128: 0.5072\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 1s 2ms/step - loss: 170.5638 - accuracy: 0.7248 - precision_128: 0.3373 - recall_128: 0.4066\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 205.4615 - accuracy: 0.7561 - precision_128: 0.3982 - recall_128: 0.4579\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 175.5755 - accuracy: 0.7752 - precision_128: 0.4350 - recall_128: 0.4600\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 232.6967 - accuracy: 0.7585 - precision_128: 0.3866 - recall_128: 0.3778\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 160.5742 - accuracy: 0.7581 - precision_128: 0.4014 - recall_128: 0.4559\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 241.1357 - accuracy: 0.7804 - precision_128: 0.4477 - recall_128: 0.4743\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 105.3282 - accuracy: 0.7431 - precision_128: 0.3673 - recall_128: 0.4148\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 175.7492 - accuracy: 0.7772 - precision_128: 0.4272 - recall_128: 0.3737\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 179.1538 - accuracy: 0.7845 - precision_128: 0.4502 - recall_128: 0.4086\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 337.5901 - accuracy: 0.7910 - precision_128: 0.4653 - recall_128: 0.3860\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 135.6926 - accuracy: 0.7869 - precision_128: 0.4614 - recall_128: 0.4661\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 205.3619 - accuracy: 0.8040 - precision_128: 0.5046 - recall_128: 0.4517\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 63.0687 - accuracy: 0.8056 - precision_128: 0.5108 - recall_128: 0.3901\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 90.8132 - accuracy: 0.7711 - precision_128: 0.4269 - recall_128: 0.4620\n",
      "Test size 0.10 + batch size 16 = [98.44790649414062, 0.808984637260437, 0.5833333134651184, 0.05273069813847542]\n",
      "Epoch 1/20\n",
      "233/233 [==============================] - 1s 2ms/step - loss: 579.0806 - accuracy: 0.7740 - precision_129: 0.4159 - recall_129: 0.3794\n",
      "Epoch 2/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 224.4088 - accuracy: 0.7602 - precision_129: 0.3750 - recall_129: 0.3355\n",
      "Epoch 3/20\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 166.7845 - accuracy: 0.7581 - precision_129: 0.3803 - recall_129: 0.3728\n",
      "Epoch 4/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 158.7687 - accuracy: 0.7413 - precision_129: 0.3447 - recall_129: 0.3553\n",
      "Epoch 5/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 103.9272 - accuracy: 0.7688 - precision_129: 0.3975 - recall_129: 0.3487\n",
      "Epoch 6/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 113.9167 - accuracy: 0.7495 - precision_129: 0.3813 - recall_129: 0.4474\n",
      "Epoch 7/20\n",
      "233/233 [==============================] - 1s 2ms/step - loss: 108.6799 - accuracy: 0.7709 - precision_129: 0.4049 - recall_129: 0.3596\n",
      "Epoch 8/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 105.8215 - accuracy: 0.7705 - precision_129: 0.4093 - recall_129: 0.3860\n",
      "Epoch 9/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 128.7610 - accuracy: 0.7636 - precision_129: 0.3941 - recall_129: 0.3838\n",
      "Epoch 10/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 107.2818 - accuracy: 0.7675 - precision_129: 0.4078 - recall_129: 0.4123\n",
      "Epoch 11/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 177.6704 - accuracy: 0.7920 - precision_129: 0.4674 - recall_129: 0.4408\n",
      "Epoch 12/20\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 379.0122 - accuracy: 0.8058 - precision_129: 0.5057 - recall_129: 0.3882\n",
      "Epoch 13/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 154.4308 - accuracy: 0.7976 - precision_129: 0.4776 - recall_129: 0.3509\n",
      "Epoch 14/20\n",
      "233/233 [==============================] - 1s 2ms/step - loss: 107.2239 - accuracy: 0.7770 - precision_129: 0.4325 - recall_129: 0.4430\n",
      "Epoch 15/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 65.3361 - accuracy: 0.7826 - precision_129: 0.4413 - recall_129: 0.4123\n",
      "Epoch 16/20\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 66.8624 - accuracy: 0.7585 - precision_129: 0.3940 - recall_129: 0.4320\n",
      "Epoch 17/20\n",
      "233/233 [==============================] - 1s 2ms/step - loss: 96.2387 - accuracy: 0.7675 - precision_129: 0.4109 - recall_129: 0.4298\n",
      "Epoch 18/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 75.9722 - accuracy: 0.7731 - precision_129: 0.4227 - recall_129: 0.4320\n",
      "Epoch 19/20\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 140.2978 - accuracy: 0.7942 - precision_129: 0.4680 - recall_129: 0.3684\n",
      "Epoch 20/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 70.7604 - accuracy: 0.7585 - precision_129: 0.3923 - recall_129: 0.4232\n",
      "Test size 0.15 + batch size 16 = [52.54240798950195, 0.8217676877975464, 0.7263157963752747, 0.12994350492954254]\n",
      "Epoch 1/20\n",
      "219/219 [==============================] - 1s 1ms/step - loss: 1321.8855 - accuracy: 0.7228 - precision_130: 0.3138 - recall_130: 0.3664\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 361.4652 - accuracy: 0.7589 - precision_130: 0.3697 - recall_130: 0.3522\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 92.3559 - accuracy: 0.7178 - precision_130: 0.3204 - recall_130: 0.4113\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 167.8661 - accuracy: 0.7269 - precision_130: 0.3406 - recall_130: 0.4421\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 481.6724 - accuracy: 0.7689 - precision_130: 0.4046 - recall_130: 0.4161\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 1052.3511 - accuracy: 0.7845 - precision_130: 0.4347 - recall_130: 0.3853\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 1037.1682 - accuracy: 0.7890 - precision_130: 0.4393 - recall_130: 0.3333\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 325.2363 - accuracy: 0.7443 - precision_130: 0.3546 - recall_130: 0.3948\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 168.1412 - accuracy: 0.7265 - precision_130: 0.3423 - recall_130: 0.4515\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 316.9799 - accuracy: 0.7557 - precision_130: 0.3857 - recall_130: 0.4468\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 97.1331 - accuracy: 0.7539 - precision_130: 0.3831 - recall_130: 0.4492\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 201.2273 - accuracy: 0.7543 - precision_130: 0.3641 - recall_130: 0.3641\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 372.4933 - accuracy: 0.7749 - precision_130: 0.3964 - recall_130: 0.3168\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 377.5243 - accuracy: 0.7776 - precision_130: 0.3242 - recall_130: 0.1395\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 0s 1ms/step - loss: 214.9062 - accuracy: 0.7744 - precision_130: 0.3680 - recall_130: 0.2340\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 186.3476 - accuracy: 0.7562 - precision_130: 0.2658 - recall_130: 0.1489\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 412.3696 - accuracy: 0.7795 - precision_130: 0.1875 - recall_130: 0.0426\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 636.7195 - accuracy: 0.7945 - precision_130: 0.2353 - recall_130: 0.0284\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 212.6837 - accuracy: 0.7735 - precision_130: 0.2336 - recall_130: 0.0757\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 87.2229 - accuracy: 0.7616 - precision_130: 0.2171 - recall_130: 0.0898\n",
      "Test size 0.20 + batch size 16 = [173.36419677734375, 0.8060628175735474, 0.5, 0.030131826177239418]\n",
      "Epoch 1/20\n",
      "206/206 [==============================] - 1s 2ms/step - loss: 365.8646 - accuracy: 0.7755 - precision_131: 0.3964 - recall_131: 0.2754\n",
      "Epoch 2/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 156.2179 - accuracy: 0.7706 - precision_131: 0.3951 - recall_131: 0.3176\n",
      "Epoch 3/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 131.9515 - accuracy: 0.7623 - precision_131: 0.3803 - recall_131: 0.3350\n",
      "Epoch 4/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 346.5266 - accuracy: 0.7589 - precision_131: 0.3729 - recall_131: 0.3350\n",
      "Epoch 5/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 319.2571 - accuracy: 0.7852 - precision_131: 0.4399 - recall_131: 0.3449\n",
      "Epoch 6/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 158.2924 - accuracy: 0.7545 - precision_131: 0.3823 - recall_131: 0.4069\n",
      "Epoch 7/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 319.2962 - accuracy: 0.7915 - precision_131: 0.4615 - recall_131: 0.3722\n",
      "Epoch 8/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 162.8491 - accuracy: 0.7618 - precision_131: 0.4069 - recall_131: 0.4665\n",
      "Epoch 9/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 187.8578 - accuracy: 0.7852 - precision_131: 0.4523 - recall_131: 0.4467\n",
      "Epoch 10/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 392.4420 - accuracy: 0.7886 - precision_131: 0.4448 - recall_131: 0.3102\n",
      "Epoch 11/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 587.7760 - accuracy: 0.7876 - precision_131: 0.4535 - recall_131: 0.3995\n",
      "Epoch 12/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 391.4309 - accuracy: 0.7808 - precision_131: 0.4342 - recall_131: 0.3846\n",
      "Epoch 13/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 186.5104 - accuracy: 0.7667 - precision_131: 0.4031 - recall_131: 0.3921\n",
      "Epoch 14/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 82.2591 - accuracy: 0.7545 - precision_131: 0.3806 - recall_131: 0.3995\n",
      "Epoch 15/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 50.3672 - accuracy: 0.7228 - precision_131: 0.3391 - recall_131: 0.4342\n",
      "Epoch 16/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 65.4847 - accuracy: 0.7711 - precision_131: 0.4193 - recall_131: 0.4318\n",
      "Epoch 17/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 267.1273 - accuracy: 0.7652 - precision_131: 0.4128 - recall_131: 0.4640\n",
      "Epoch 18/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 226.2118 - accuracy: 0.8027 - precision_131: 0.4973 - recall_131: 0.4491\n",
      "Epoch 19/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 83.5472 - accuracy: 0.7837 - precision_131: 0.4435 - recall_131: 0.3995\n",
      "Epoch 20/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 51.2667 - accuracy: 0.7793 - precision_131: 0.4369 - recall_131: 0.4293\n",
      "Test size 0.25 + batch size 16 = [97.03697967529297, 0.7618699669837952, 0.43611404299736023, 0.7777777910232544]\n",
      "Epoch 1/20\n",
      "192/192 [==============================] - 2s 2ms/step - loss: 310.4986 - accuracy: 0.7500 - precision_132: 0.3486 - recall_132: 0.3515\n",
      "Epoch 2/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 133.3201 - accuracy: 0.7636 - precision_132: 0.3750 - recall_132: 0.3515\n",
      "Epoch 3/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 402.8655 - accuracy: 0.7630 - precision_132: 0.3827 - recall_132: 0.3869\n",
      "Epoch 4/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 294.8578 - accuracy: 0.7683 - precision_132: 0.3945 - recall_132: 0.3924\n",
      "Epoch 5/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 442.8339 - accuracy: 0.7876 - precision_132: 0.4355 - recall_132: 0.3678\n",
      "Epoch 6/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 105.3851 - accuracy: 0.7370 - precision_132: 0.3508 - recall_132: 0.4387\n",
      "Epoch 7/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 417.4394 - accuracy: 0.7777 - precision_132: 0.4087 - recall_132: 0.3597\n",
      "Epoch 8/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 262.6362 - accuracy: 0.7871 - precision_132: 0.4419 - recall_132: 0.4251\n",
      "Epoch 9/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 91.1609 - accuracy: 0.7636 - precision_132: 0.3920 - recall_132: 0.4251\n",
      "Epoch 10/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 51.0413 - accuracy: 0.7338 - precision_132: 0.3495 - recall_132: 0.4523\n",
      "Epoch 11/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 75.6956 - accuracy: 0.7516 - precision_132: 0.3620 - recall_132: 0.3896\n",
      "Epoch 12/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 151.9267 - accuracy: 0.7777 - precision_132: 0.4140 - recall_132: 0.3869\n",
      "Epoch 13/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 146.6927 - accuracy: 0.7568 - precision_132: 0.3666 - recall_132: 0.3706\n",
      "Epoch 14/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 151.6265 - accuracy: 0.7970 - precision_132: 0.4650 - recall_132: 0.3978\n",
      "Epoch 15/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 81.2332 - accuracy: 0.7751 - precision_132: 0.4111 - recall_132: 0.4033\n",
      "Epoch 16/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 492.7007 - accuracy: 0.7965 - precision_132: 0.4676 - recall_132: 0.4523\n",
      "Epoch 17/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 430.3772 - accuracy: 0.8032 - precision_132: 0.4821 - recall_132: 0.3678\n",
      "Epoch 18/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 213.4907 - accuracy: 0.7813 - precision_132: 0.4316 - recall_132: 0.4469\n",
      "Epoch 19/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 58.6373 - accuracy: 0.7469 - precision_132: 0.3761 - recall_132: 0.4877\n",
      "Epoch 20/20\n",
      "192/192 [==============================] - 0s 1ms/step - loss: 359.2419 - accuracy: 0.8011 - precision_132: 0.4790 - recall_132: 0.4360\n",
      "Test size 0.30 + batch size 16 = [314.24163818359375, 0.7647918462753296, 0.43957218527793884, 0.7740113139152527]\n",
      "Epoch 1/20\n",
      "178/178 [==============================] - 1s 1ms/step - loss: 937.9012 - accuracy: 0.6813 - precision_133: 0.2545 - recall_133: 0.3238\n",
      "Epoch 2/20\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 207.9214 - accuracy: 0.7189 - precision_133: 0.3089 - recall_133: 0.3496\n",
      "Epoch 3/20\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 261.0702 - accuracy: 0.7662 - precision_133: 0.3745 - recall_133: 0.2865\n",
      "Epoch 4/20\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 1047.9392 - accuracy: 0.7752 - precision_133: 0.4234 - recall_133: 0.4040\n",
      "Epoch 5/20\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 214.4178 - accuracy: 0.7156 - precision_133: 0.3290 - recall_133: 0.4327\n",
      "Epoch 6/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 123.6211 - accuracy: 0.7358 - precision_133: 0.3506 - recall_133: 0.4069\n",
      "Epoch 7/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 103.0350 - accuracy: 0.7392 - precision_133: 0.3666 - recall_133: 0.4527\n",
      "Epoch 8/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 210.4558 - accuracy: 0.7572 - precision_133: 0.3857 - recall_133: 0.4011\n",
      "Epoch 9/20\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 144.4325 - accuracy: 0.7577 - precision_133: 0.3848 - recall_133: 0.3926\n",
      "Epoch 10/20\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 176.1459 - accuracy: 0.7707 - precision_133: 0.4130 - recall_133: 0.4011\n",
      "Epoch 11/20\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 103.6383 - accuracy: 0.7808 - precision_133: 0.4459 - recall_133: 0.4842\n",
      "Epoch 12/20\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 397.3078 - accuracy: 0.7684 - precision_133: 0.4127 - recall_133: 0.4269\n",
      "Epoch 13/20\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 368.8541 - accuracy: 0.7988 - precision_133: 0.4865 - recall_133: 0.4642\n",
      "Epoch 14/20\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 146.3746 - accuracy: 0.7729 - precision_133: 0.4179 - recall_133: 0.4011\n",
      "Epoch 15/20\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 132.0542 - accuracy: 0.7684 - precision_133: 0.4097 - recall_133: 0.4097\n",
      "Epoch 16/20\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 281.9226 - accuracy: 0.7858 - precision_133: 0.4474 - recall_133: 0.3897\n",
      "Epoch 17/20\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 962.4590 - accuracy: 0.7960 - precision_133: 0.4774 - recall_133: 0.4241\n",
      "Epoch 18/20\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 796.0841 - accuracy: 0.8004 - precision_133: 0.4895 - recall_133: 0.4011\n",
      "Epoch 19/20\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 230.4140 - accuracy: 0.7870 - precision_133: 0.4519 - recall_133: 0.4040\n",
      "Epoch 20/20\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 219.1030 - accuracy: 0.7864 - precision_133: 0.4448 - recall_133: 0.3582\n",
      "Test size 0.35 + batch size 16 = [116.60719299316406, 0.7604090571403503, 0.43441763520240784, 0.7796609997749329]\n",
      "Epoch 1/20\n",
      "165/165 [==============================] - 1s 2ms/step - loss: 653.1572 - accuracy: 0.7576 - precision_134: 0.3448 - recall_134: 0.2839\n",
      "Epoch 2/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1185.5829 - accuracy: 0.7759 - precision_134: 0.4086 - recall_134: 0.3596\n",
      "Epoch 3/20\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 663.4424 - accuracy: 0.7814 - precision_134: 0.4198 - recall_134: 0.3470\n",
      "Epoch 4/20\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 181.5651 - accuracy: 0.7363 - precision_134: 0.3457 - recall_134: 0.4101\n",
      "Epoch 5/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 122.7751 - accuracy: 0.7156 - precision_134: 0.3077 - recall_134: 0.3785\n",
      "Epoch 6/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 181.7930 - accuracy: 0.7521 - precision_134: 0.3828 - recall_134: 0.4637\n",
      "Epoch 7/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 119.2366 - accuracy: 0.7515 - precision_134: 0.3609 - recall_134: 0.3722\n",
      "Epoch 8/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 392.3422 - accuracy: 0.7661 - precision_134: 0.3894 - recall_134: 0.3722\n",
      "Epoch 9/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 342.0728 - accuracy: 0.7747 - precision_134: 0.4114 - recall_134: 0.3880\n",
      "Epoch 10/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 709.9767 - accuracy: 0.7582 - precision_134: 0.3582 - recall_134: 0.3186\n",
      "Epoch 11/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 434.6337 - accuracy: 0.7856 - precision_134: 0.4422 - recall_134: 0.4227\n",
      "Epoch 12/20\n",
      "165/165 [==============================] - 0s 3ms/step - loss: 543.7525 - accuracy: 0.7582 - precision_134: 0.3773 - recall_134: 0.3880\n",
      "Epoch 13/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 370.2390 - accuracy: 0.7637 - precision_134: 0.3813 - recall_134: 0.3596\n",
      "Epoch 14/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 176.2691 - accuracy: 0.6857 - precision_134: 0.2813 - recall_134: 0.4038\n",
      "Epoch 15/20\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 97.3419 - accuracy: 0.7655 - precision_134: 0.4091 - recall_134: 0.4826\n",
      "Epoch 16/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 203.7643 - accuracy: 0.7789 - precision_134: 0.4102 - recall_134: 0.3312\n",
      "Epoch 17/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 121.7991 - accuracy: 0.7607 - precision_134: 0.3288 - recall_134: 0.2303\n",
      "Epoch 18/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 407.8040 - accuracy: 0.7832 - precision_134: 0.3617 - recall_134: 0.1609\n",
      "Epoch 19/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 336.9657 - accuracy: 0.7923 - precision_134: 0.3235 - recall_134: 0.0694\n",
      "Epoch 20/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 121.5269 - accuracy: 0.7826 - precision_134: 0.3851 - recall_134: 0.2114\n",
      "Test size 0.40 + batch size 16 = [27.798622131347656, 0.7680788636207581, 0.4061371982097626, 0.4237288236618042]\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 1s 2ms/step - loss: 2468.2253 - accuracy: 0.7349 - precision_135: 0.3503 - recall_135: 0.4232\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 134.5134 - accuracy: 0.7661 - precision_135: 0.4000 - recall_135: 0.4027\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 308.6382 - accuracy: 0.7748 - precision_135: 0.3964 - recall_135: 0.3003\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 241.0466 - accuracy: 0.7621 - precision_135: 0.3852 - recall_135: 0.3720\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 191.3270 - accuracy: 0.7555 - precision_135: 0.3665 - recall_135: 0.3515\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 465.5312 - accuracy: 0.7449 - precision_135: 0.3518 - recall_135: 0.3686\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 398.6983 - accuracy: 0.7860 - precision_135: 0.4453 - recall_135: 0.4027\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 204.8389 - accuracy: 0.7668 - precision_135: 0.4082 - recall_135: 0.4403\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 263.5677 - accuracy: 0.7621 - precision_135: 0.3810 - recall_135: 0.3549\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 186.3830 - accuracy: 0.7628 - precision_135: 0.4024 - recall_135: 0.4505\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 253.3643 - accuracy: 0.8053 - precision_135: 0.5000 - recall_135: 0.3686\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 216.6288 - accuracy: 0.7708 - precision_135: 0.4000 - recall_135: 0.3549\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 548.8728 - accuracy: 0.8040 - precision_135: 0.4957 - recall_135: 0.3959\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 138.3155 - accuracy: 0.7615 - precision_135: 0.3878 - recall_135: 0.3891\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 213.7072 - accuracy: 0.7462 - precision_135: 0.3794 - recall_135: 0.4778\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 273.4218 - accuracy: 0.7854 - precision_135: 0.4513 - recall_135: 0.4744\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 0s 3ms/step - loss: 270.3593 - accuracy: 0.7787 - precision_135: 0.4301 - recall_135: 0.4198\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 235.9237 - accuracy: 0.7761 - precision_135: 0.4179 - recall_135: 0.3823\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 248.2099 - accuracy: 0.7900 - precision_135: 0.4613 - recall_135: 0.4676\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 108.3211 - accuracy: 0.7668 - precision_135: 0.4162 - recall_135: 0.4915\n",
      "Test size 0.45 + batch size 16 = [228.42276000976562, 0.7618699669837952, 0.43624868988990784, 0.7796609997749329]\n",
      "Epoch 1/20\n",
      "137/137 [==============================] - 1s 1ms/step - loss: 329.8712 - accuracy: 0.7341 - precision_136: 0.3546 - recall_136: 0.4066\n",
      "Epoch 2/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 344.8100 - accuracy: 0.7604 - precision_136: 0.4068 - recall_136: 0.4396\n",
      "Epoch 3/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 204.7035 - accuracy: 0.7224 - precision_136: 0.3302 - recall_136: 0.3810\n",
      "Epoch 4/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 366.7073 - accuracy: 0.7495 - precision_136: 0.3906 - recall_136: 0.4579\n",
      "Epoch 5/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 260.5964 - accuracy: 0.7765 - precision_136: 0.4391 - recall_136: 0.4359\n",
      "Epoch 6/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 756.0662 - accuracy: 0.7692 - precision_136: 0.3909 - recall_136: 0.2821\n",
      "Epoch 7/20\n",
      "137/137 [==============================] - 0s 1ms/step - loss: 1026.3623 - accuracy: 0.7721 - precision_136: 0.4229 - recall_136: 0.3919\n",
      "Epoch 8/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 581.7064 - accuracy: 0.8020 - precision_136: 0.5040 - recall_136: 0.4579\n",
      "Epoch 9/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 207.7612 - accuracy: 0.7560 - precision_136: 0.3891 - recall_136: 0.3919\n",
      "Epoch 10/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 251.0378 - accuracy: 0.7480 - precision_136: 0.3784 - recall_136: 0.4103\n",
      "Epoch 11/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 285.3361 - accuracy: 0.7173 - precision_136: 0.3185 - recall_136: 0.3663\n",
      "Epoch 12/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 123.0859 - accuracy: 0.7699 - precision_136: 0.4180 - recall_136: 0.3919\n",
      "Epoch 13/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 416.9352 - accuracy: 0.7721 - precision_136: 0.4191 - recall_136: 0.3700\n",
      "Epoch 14/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 1045.9213 - accuracy: 0.7889 - precision_136: 0.4690 - recall_136: 0.4432\n",
      "Epoch 15/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 623.7867 - accuracy: 0.7962 - precision_136: 0.4891 - recall_136: 0.4908\n",
      "Epoch 16/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 257.3010 - accuracy: 0.7991 - precision_136: 0.4956 - recall_136: 0.4103\n",
      "Epoch 17/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 765.0387 - accuracy: 0.7845 - precision_136: 0.4601 - recall_136: 0.4652\n",
      "Epoch 18/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 641.0942 - accuracy: 0.7977 - precision_136: 0.4903 - recall_136: 0.3700\n",
      "Epoch 19/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 327.6456 - accuracy: 0.7955 - precision_136: 0.4850 - recall_136: 0.4139\n",
      "Epoch 20/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 118.2624 - accuracy: 0.7049 - precision_136: 0.3444 - recall_136: 0.5311\n",
      "Test size 0.50 + batch size 16 = [63.901695251464844, 0.7571219801902771, 0.30747127532958984, 0.2015065848827362]\n",
      "Epoch 1/20\n",
      "247/247 [==============================] - 1s 2ms/step - loss: 1167.6837 - accuracy: 0.7358 - precision_137: 0.3694 - recall_137: 0.4764\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 176.3975 - accuracy: 0.7557 - precision_137: 0.3805 - recall_137: 0.3758\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 859.4695 - accuracy: 0.7699 - precision_137: 0.3947 - recall_137: 0.3080\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 364.8472 - accuracy: 0.7877 - precision_137: 0.4543 - recall_137: 0.3676\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 121.3161 - accuracy: 0.6993 - precision_137: 0.3143 - recall_137: 0.4415\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 154.0980 - accuracy: 0.7415 - precision_137: 0.3702 - recall_137: 0.4394\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 754.4192 - accuracy: 0.7792 - precision_137: 0.4188 - recall_137: 0.3018\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 582.7408 - accuracy: 0.7837 - precision_137: 0.4465 - recall_137: 0.3943\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 135.9658 - accuracy: 0.7378 - precision_137: 0.3312 - recall_137: 0.3203\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 0s 1ms/step - loss: 94.3129 - accuracy: 0.7269 - precision_137: 0.3490 - recall_137: 0.4415\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 1s 2ms/step - loss: 79.7175 - accuracy: 0.7192 - precision_137: 0.3098 - recall_137: 0.3429\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 205.8145 - accuracy: 0.7606 - precision_137: 0.3992 - recall_137: 0.4189\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 226.0952 - accuracy: 0.7443 - precision_137: 0.3653 - recall_137: 0.3984\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 96.0953 - accuracy: 0.7362 - precision_137: 0.3616 - recall_137: 0.4374\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 136.1828 - accuracy: 0.7662 - precision_137: 0.4143 - recall_137: 0.4415\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 146.6084 - accuracy: 0.7776 - precision_137: 0.4391 - recall_137: 0.4517\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 154.1614 - accuracy: 0.7719 - precision_137: 0.4172 - recall_137: 0.3881\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 81.3243 - accuracy: 0.7537 - precision_137: 0.3962 - recall_137: 0.4702\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 177.4908 - accuracy: 0.7800 - precision_137: 0.4440 - recall_137: 0.4476\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 0s 2ms/step - loss: 127.5945 - accuracy: 0.7394 - precision_137: 0.3614 - recall_137: 0.4148\n",
      "Test size 0.10 + batch size 32 = [113.43572235107422, 0.7914535999298096, 0.2777777910232544, 0.047080978751182556]\n",
      "Epoch 1/20\n",
      "233/233 [==============================] - 1s 2ms/step - loss: 410.8843 - accuracy: 0.7555 - precision_138: 0.3695 - recall_138: 0.3509\n",
      "Epoch 2/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 212.4179 - accuracy: 0.7576 - precision_138: 0.3670 - recall_138: 0.3268\n",
      "Epoch 3/20\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 199.8960 - accuracy: 0.7679 - precision_138: 0.4045 - recall_138: 0.3904\n",
      "Epoch 4/20\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 206.4418 - accuracy: 0.7576 - precision_138: 0.3601 - recall_138: 0.3048\n",
      "Epoch 5/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 464.4873 - accuracy: 0.7658 - precision_138: 0.3873 - recall_138: 0.3355\n",
      "Epoch 6/20\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 971.0045 - accuracy: 0.7778 - precision_138: 0.4232 - recall_138: 0.3684\n",
      "Epoch 7/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 218.0005 - accuracy: 0.7477 - precision_138: 0.3713 - recall_138: 0.4145\n",
      "Epoch 8/20\n",
      "233/233 [==============================] - 0s 1ms/step - loss: 168.9480 - accuracy: 0.7529 - precision_138: 0.3758 - recall_138: 0.3947\n",
      "Epoch 9/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 194.9162 - accuracy: 0.7344 - precision_138: 0.3360 - recall_138: 0.3640\n",
      "Epoch 10/20\n",
      "233/233 [==============================] - 1s 3ms/step - loss: 248.5653 - accuracy: 0.7804 - precision_138: 0.4347 - recall_138: 0.4013\n",
      "Epoch 11/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 111.4262 - accuracy: 0.7589 - precision_138: 0.3885 - recall_138: 0.4013\n",
      "Epoch 12/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 241.4689 - accuracy: 0.7795 - precision_138: 0.4240 - recall_138: 0.3487\n",
      "Epoch 13/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 132.2100 - accuracy: 0.7731 - precision_138: 0.4256 - recall_138: 0.4518\n",
      "Epoch 14/20\n",
      "233/233 [==============================] - 1s 2ms/step - loss: 181.7290 - accuracy: 0.7735 - precision_138: 0.4184 - recall_138: 0.3991\n",
      "Epoch 15/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 201.3092 - accuracy: 0.7864 - precision_138: 0.4515 - recall_138: 0.4189\n",
      "Epoch 16/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 229.9135 - accuracy: 0.8002 - precision_138: 0.4897 - recall_138: 0.4693\n",
      "Epoch 17/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 589.8757 - accuracy: 0.8028 - precision_138: 0.4956 - recall_138: 0.3684\n",
      "Epoch 18/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 618.8573 - accuracy: 0.8019 - precision_138: 0.4935 - recall_138: 0.4189\n",
      "Epoch 19/20\n",
      "233/233 [==============================] - 1s 2ms/step - loss: 227.7590 - accuracy: 0.7413 - precision_138: 0.3557 - recall_138: 0.3947\n",
      "Epoch 20/20\n",
      "233/233 [==============================] - 0s 2ms/step - loss: 332.8541 - accuracy: 0.7598 - precision_138: 0.3883 - recall_138: 0.3925\n",
      "Test size 0.15 + batch size 32 = [987.4849243164062, 0.7688093781471252, 0.4443231523036957, 0.7664783596992493]\n",
      "Epoch 1/20\n",
      "219/219 [==============================] - 2s 2ms/step - loss: 232.6342 - accuracy: 0.6890 - precision_139: 0.2997 - recall_139: 0.4563\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 142.7204 - accuracy: 0.7279 - precision_139: 0.3561 - recall_139: 0.5059\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 183.3935 - accuracy: 0.7178 - precision_139: 0.3062 - recall_139: 0.3641\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 257.9866 - accuracy: 0.7479 - precision_139: 0.3431 - recall_139: 0.3333\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 388.7986 - accuracy: 0.7918 - precision_139: 0.4589 - recall_139: 0.4350\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 172.9650 - accuracy: 0.8064 - precision_139: 0.4986 - recall_139: 0.4232\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 129.0029 - accuracy: 0.7406 - precision_139: 0.3564 - recall_139: 0.4255\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 142.9068 - accuracy: 0.7498 - precision_139: 0.3684 - recall_139: 0.4137\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 144.7230 - accuracy: 0.7475 - precision_139: 0.3495 - recall_139: 0.3570\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 171.3226 - accuracy: 0.7612 - precision_139: 0.3908 - recall_139: 0.4232\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 89.9770 - accuracy: 0.7785 - precision_139: 0.4201 - recall_139: 0.3853\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 97.6955 - accuracy: 0.7858 - precision_139: 0.4439 - recall_139: 0.4303\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 118.1042 - accuracy: 0.7785 - precision_139: 0.4295 - recall_139: 0.4468\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 108.2868 - accuracy: 0.7922 - precision_139: 0.4563 - recall_139: 0.3948\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 120.3304 - accuracy: 0.7840 - precision_139: 0.4419 - recall_139: 0.4492\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 105.2724 - accuracy: 0.7900 - precision_139: 0.4567 - recall_139: 0.4610\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 148.3060 - accuracy: 0.7763 - precision_139: 0.4185 - recall_139: 0.4066\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 109.9480 - accuracy: 0.7795 - precision_139: 0.4330 - recall_139: 0.4586\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 138.7308 - accuracy: 0.8123 - precision_139: 0.5171 - recall_139: 0.4279\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 56.4103 - accuracy: 0.7822 - precision_139: 0.4381 - recall_139: 0.4515\n",
      "Test size 0.20 + batch size 32 = [29.380510330200195, 0.7403213977813721, 0.4163568913936615, 0.8436911702156067]\n",
      "Epoch 1/20\n",
      "206/206 [==============================] - 1s 2ms/step - loss: 758.2230 - accuracy: 0.7457 - precision_140: 0.3305 - recall_140: 0.2878\n",
      "Epoch 2/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 187.9198 - accuracy: 0.7681 - precision_140: 0.4099 - recall_140: 0.4119\n",
      "Epoch 3/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 239.1667 - accuracy: 0.7584 - precision_140: 0.3805 - recall_140: 0.3672\n",
      "Epoch 4/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 305.8244 - accuracy: 0.7852 - precision_140: 0.4497 - recall_140: 0.4218\n",
      "Epoch 5/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 284.0370 - accuracy: 0.7696 - precision_140: 0.4116 - recall_140: 0.4045\n",
      "Epoch 6/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 250.7562 - accuracy: 0.7584 - precision_140: 0.3792 - recall_140: 0.3623\n",
      "Epoch 7/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 316.3236 - accuracy: 0.7618 - precision_140: 0.3936 - recall_140: 0.3945\n",
      "Epoch 8/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 196.6597 - accuracy: 0.7340 - precision_140: 0.3422 - recall_140: 0.3846\n",
      "Epoch 9/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 152.4467 - accuracy: 0.7394 - precision_140: 0.3429 - recall_140: 0.3573\n",
      "Epoch 10/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 199.4889 - accuracy: 0.7623 - precision_140: 0.4036 - recall_140: 0.4417\n",
      "Epoch 11/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 203.6489 - accuracy: 0.7662 - precision_140: 0.4103 - recall_140: 0.4367\n",
      "Epoch 12/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 214.2824 - accuracy: 0.7647 - precision_140: 0.4065 - recall_140: 0.4318\n",
      "Epoch 13/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 115.0711 - accuracy: 0.7594 - precision_140: 0.3904 - recall_140: 0.4020\n",
      "Epoch 14/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 127.6695 - accuracy: 0.7604 - precision_140: 0.4004 - recall_140: 0.4442\n",
      "Epoch 15/20\n",
      "206/206 [==============================] - 1s 3ms/step - loss: 243.9228 - accuracy: 0.7871 - precision_140: 0.4530 - recall_140: 0.4069\n",
      "Epoch 16/20\n",
      "206/206 [==============================] - 1s 3ms/step - loss: 914.3086 - accuracy: 0.7735 - precision_140: 0.4119 - recall_140: 0.3598\n",
      "Epoch 17/20\n",
      "206/206 [==============================] - 1s 3ms/step - loss: 483.1856 - accuracy: 0.7862 - precision_140: 0.4467 - recall_140: 0.3747\n",
      "Epoch 18/20\n",
      "206/206 [==============================] - 1s 2ms/step - loss: 163.4292 - accuracy: 0.7647 - precision_140: 0.4065 - recall_140: 0.4318\n",
      "Epoch 19/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 125.2844 - accuracy: 0.7823 - precision_140: 0.4436 - recall_140: 0.4293\n",
      "Epoch 20/20\n",
      "206/206 [==============================] - 0s 2ms/step - loss: 217.5000 - accuracy: 0.7462 - precision_140: 0.3745 - recall_140: 0.4367\n",
      "Test size 0.25 + batch size 32 = [20.197620391845703, 0.5219138264656067, 0.13022813200950623, 0.25800377130508423]\n",
      "Epoch 1/20\n",
      "192/192 [==============================] - 1s 2ms/step - loss: 1723.1113 - accuracy: 0.7286 - precision_141: 0.2675 - recall_141: 0.2398\n",
      "Epoch 2/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 139.6360 - accuracy: 0.7448 - precision_141: 0.3541 - recall_141: 0.4033\n",
      "Epoch 3/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 782.2146 - accuracy: 0.7730 - precision_141: 0.3828 - recall_141: 0.3025\n",
      "Epoch 4/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 139.6481 - accuracy: 0.7396 - precision_141: 0.3413 - recall_141: 0.3869\n",
      "Epoch 5/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 178.6629 - accuracy: 0.7573 - precision_141: 0.3828 - recall_141: 0.4360\n",
      "Epoch 6/20\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 201.1001 - accuracy: 0.7364 - precision_141: 0.3231 - recall_141: 0.3433\n",
      "Epoch 7/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 249.7675 - accuracy: 0.7557 - precision_141: 0.3688 - recall_141: 0.3869\n",
      "Epoch 8/20\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 357.7505 - accuracy: 0.7745 - precision_141: 0.4006 - recall_141: 0.3569\n",
      "Epoch 9/20\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 303.8259 - accuracy: 0.7818 - precision_141: 0.4290 - recall_141: 0.4196\n",
      "Epoch 10/20\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 913.7253 - accuracy: 0.7886 - precision_141: 0.4307 - recall_141: 0.3215\n",
      "Epoch 11/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 201.3122 - accuracy: 0.7740 - precision_141: 0.4073 - recall_141: 0.3951\n",
      "Epoch 12/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 178.9716 - accuracy: 0.7636 - precision_141: 0.3903 - recall_141: 0.4169\n",
      "Epoch 13/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 305.3448 - accuracy: 0.7996 - precision_141: 0.4725 - recall_141: 0.3978\n",
      "Epoch 14/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 199.6372 - accuracy: 0.7385 - precision_141: 0.3389 - recall_141: 0.3842\n",
      "Epoch 15/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 155.1325 - accuracy: 0.7745 - precision_141: 0.4213 - recall_141: 0.4741\n",
      "Epoch 16/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 175.0078 - accuracy: 0.7390 - precision_141: 0.3443 - recall_141: 0.4005\n",
      "Epoch 17/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 220.1421 - accuracy: 0.7865 - precision_141: 0.4403 - recall_141: 0.4223\n",
      "Epoch 18/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 315.9315 - accuracy: 0.7787 - precision_141: 0.4144 - recall_141: 0.3760\n",
      "Epoch 19/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 164.9397 - accuracy: 0.7751 - precision_141: 0.4135 - recall_141: 0.4169\n",
      "Epoch 20/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 100.3882 - accuracy: 0.7808 - precision_141: 0.4089 - recall_141: 0.3243\n",
      "Test size 0.30 + batch size 32 = [139.0400390625, 0.8046019077301025, 0.44117647409439087, 0.028248587623238564]\n",
      "Epoch 1/20\n",
      "178/178 [==============================] - 1s 2ms/step - loss: 1091.6932 - accuracy: 0.7560 - precision_142: 0.3659 - recall_142: 0.3324\n",
      "Epoch 2/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 257.3683 - accuracy: 0.7926 - precision_142: 0.4667 - recall_142: 0.4011\n",
      "Epoch 3/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 230.9784 - accuracy: 0.7330 - precision_142: 0.3425 - recall_142: 0.3926\n",
      "Epoch 4/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 303.1970 - accuracy: 0.7729 - precision_142: 0.3978 - recall_142: 0.3066\n",
      "Epoch 5/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 234.8327 - accuracy: 0.7611 - precision_142: 0.3848 - recall_142: 0.3639\n",
      "Epoch 6/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 562.5396 - accuracy: 0.7740 - precision_142: 0.4204 - recall_142: 0.4011\n",
      "Epoch 7/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 663.7643 - accuracy: 0.7645 - precision_142: 0.3856 - recall_142: 0.3381\n",
      "Epoch 8/20\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 437.7389 - accuracy: 0.7774 - precision_142: 0.4303 - recall_142: 0.4155\n",
      "Epoch 9/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 315.2224 - accuracy: 0.7808 - precision_142: 0.4429 - recall_142: 0.4556\n",
      "Epoch 10/20\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 326.9037 - accuracy: 0.7566 - precision_142: 0.3786 - recall_142: 0.3754\n",
      "Epoch 11/20\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 772.1171 - accuracy: 0.8033 - precision_142: 0.4983 - recall_142: 0.4212\n",
      "Epoch 12/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 356.3974 - accuracy: 0.7628 - precision_142: 0.4021 - recall_142: 0.4298\n",
      "Epoch 13/20\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 396.9647 - accuracy: 0.7797 - precision_142: 0.4256 - recall_142: 0.3524\n",
      "Epoch 14/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 521.8164 - accuracy: 0.7707 - precision_142: 0.4169 - recall_142: 0.4241\n",
      "Epoch 15/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 225.1297 - accuracy: 0.7645 - precision_142: 0.4069 - recall_142: 0.4384\n",
      "Epoch 16/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 292.3662 - accuracy: 0.7673 - precision_142: 0.4100 - recall_142: 0.4241\n",
      "Epoch 17/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 205.2736 - accuracy: 0.7695 - precision_142: 0.4258 - recall_142: 0.5014\n",
      "Epoch 18/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 330.3005 - accuracy: 0.7763 - precision_142: 0.4232 - recall_142: 0.3868\n",
      "Epoch 19/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 839.8746 - accuracy: 0.8173 - precision_142: 0.5387 - recall_142: 0.4785\n",
      "Epoch 20/20\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 319.6785 - accuracy: 0.7886 - precision_142: 0.4526 - recall_142: 0.3696\n",
      "Test size 0.35 + batch size 32 = [106.03509521484375, 0.8290722966194153, 0.7058823704719543, 0.20338982343673706]\n",
      "Epoch 1/20\n",
      "165/165 [==============================] - 1s 2ms/step - loss: 687.0120 - accuracy: 0.7808 - precision_143: 0.4286 - recall_143: 0.4069\n",
      "Epoch 2/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 255.6436 - accuracy: 0.7643 - precision_143: 0.3878 - recall_143: 0.3817\n",
      "Epoch 3/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 129.9408 - accuracy: 0.7132 - precision_143: 0.3242 - recall_143: 0.4479\n",
      "Epoch 4/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 151.6369 - accuracy: 0.7272 - precision_143: 0.3466 - recall_143: 0.4669\n",
      "Epoch 5/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 198.0835 - accuracy: 0.7400 - precision_143: 0.3323 - recall_143: 0.3438\n",
      "Epoch 6/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 345.9557 - accuracy: 0.7728 - precision_143: 0.4195 - recall_143: 0.4606\n",
      "Epoch 7/20\n",
      "165/165 [==============================] - 1s 4ms/step - loss: 170.3644 - accuracy: 0.7430 - precision_143: 0.3615 - recall_143: 0.4322\n",
      "Epoch 8/20\n",
      "165/165 [==============================] - 1s 3ms/step - loss: 437.8111 - accuracy: 0.7893 - precision_143: 0.4436 - recall_143: 0.3596\n",
      "Epoch 9/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 196.3979 - accuracy: 0.7473 - precision_143: 0.3608 - recall_143: 0.4006\n",
      "Epoch 10/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 223.1393 - accuracy: 0.7820 - precision_143: 0.4232 - recall_143: 0.3565\n",
      "Epoch 11/20\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 116.6244 - accuracy: 0.7540 - precision_143: 0.3821 - recall_143: 0.4448\n",
      "Epoch 12/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 567.3096 - accuracy: 0.7850 - precision_143: 0.4477 - recall_143: 0.4858\n",
      "Epoch 13/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 507.5562 - accuracy: 0.7832 - precision_143: 0.4365 - recall_143: 0.4227\n",
      "Epoch 14/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 324.1264 - accuracy: 0.8002 - precision_143: 0.4753 - recall_143: 0.3344\n",
      "Epoch 15/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 284.0180 - accuracy: 0.7704 - precision_143: 0.4080 - recall_143: 0.4196\n",
      "Epoch 16/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 276.7742 - accuracy: 0.7515 - precision_143: 0.3718 - recall_143: 0.4164\n",
      "Epoch 17/20\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 335.9588 - accuracy: 0.8002 - precision_143: 0.4794 - recall_143: 0.4038\n",
      "Epoch 18/20\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 201.3469 - accuracy: 0.8094 - precision_143: 0.5086 - recall_143: 0.3722\n",
      "Epoch 19/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 115.4527 - accuracy: 0.7686 - precision_143: 0.4146 - recall_143: 0.4826\n",
      "Epoch 20/20\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 163.2586 - accuracy: 0.8179 - precision_143: 0.5425 - recall_143: 0.3628\n",
      "Test size 0.40 + batch size 32 = [175.8601531982422, 0.6895543932914734, 0.36979591846466064, 0.8531073331832886]\n",
      "Epoch 1/20\n",
      "151/151 [==============================] - 1s 1ms/step - loss: 490.5827 - accuracy: 0.7342 - precision_144: 0.3186 - recall_144: 0.3208\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 241.6133 - accuracy: 0.7296 - precision_144: 0.3283 - recall_144: 0.3720\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 279.6490 - accuracy: 0.7196 - precision_144: 0.2885 - recall_144: 0.3003\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 335.5461 - accuracy: 0.7508 - precision_144: 0.3660 - recall_144: 0.3823\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 410.4850 - accuracy: 0.7475 - precision_144: 0.3515 - recall_144: 0.3515\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 392.2144 - accuracy: 0.7635 - precision_144: 0.3953 - recall_144: 0.4061\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 334.1139 - accuracy: 0.7355 - precision_144: 0.3538 - recall_144: 0.4334\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 223.3692 - accuracy: 0.7701 - precision_144: 0.4089 - recall_144: 0.4061\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 464.7562 - accuracy: 0.7674 - precision_144: 0.4139 - recall_144: 0.4676\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 778.4573 - accuracy: 0.7787 - precision_144: 0.4231 - recall_144: 0.3754\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 460.8037 - accuracy: 0.7920 - precision_144: 0.4590 - recall_144: 0.3823\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 402.3391 - accuracy: 0.7641 - precision_144: 0.3938 - recall_144: 0.3925\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 709.8289 - accuracy: 0.7927 - precision_144: 0.4625 - recall_144: 0.3993\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 0s 2ms/step - loss: 439.4998 - accuracy: 0.7867 - precision_144: 0.4369 - recall_144: 0.3311\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 169.8719 - accuracy: 0.7223 - precision_144: 0.3402 - recall_144: 0.4539\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 137.6728 - accuracy: 0.6844 - precision_144: 0.2884 - recall_144: 0.4232\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 190.9112 - accuracy: 0.7741 - precision_144: 0.4244 - recall_144: 0.4505\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 126.7238 - accuracy: 0.7475 - precision_144: 0.3678 - recall_144: 0.4130\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 274.2863 - accuracy: 0.7681 - precision_144: 0.3978 - recall_144: 0.3720\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 0s 1ms/step - loss: 155.7912 - accuracy: 0.7980 - precision_144: 0.4792 - recall_144: 0.4334\n",
      "Test size 0.45 + batch size 32 = [38.46612548828125, 0.7472607493400574, 0.27823692560195923, 0.19020715355873108]\n",
      "Epoch 1/20\n",
      "137/137 [==============================] - 1s 2ms/step - loss: 522.6974 - accuracy: 0.7436 - precision_145: 0.3545 - recall_145: 0.3480\n",
      "Epoch 2/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 302.0115 - accuracy: 0.7400 - precision_145: 0.3648 - recall_145: 0.4103\n",
      "Epoch 3/20\n",
      "137/137 [==============================] - 0s 3ms/step - loss: 205.1964 - accuracy: 0.7107 - precision_145: 0.3153 - recall_145: 0.3846\n",
      "Epoch 4/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 448.0779 - accuracy: 0.7195 - precision_145: 0.3192 - recall_145: 0.3590\n",
      "Epoch 5/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 960.8757 - accuracy: 0.7838 - precision_145: 0.4410 - recall_145: 0.3150\n",
      "Epoch 6/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 123.1020 - accuracy: 0.7217 - precision_145: 0.3163 - recall_145: 0.3407\n",
      "Epoch 7/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 97.4866 - accuracy: 0.7327 - precision_145: 0.3434 - recall_145: 0.3736\n",
      "Epoch 8/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 489.7154 - accuracy: 0.7575 - precision_145: 0.3677 - recall_145: 0.3004\n",
      "Epoch 9/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 231.5519 - accuracy: 0.7582 - precision_145: 0.3739 - recall_145: 0.3150\n",
      "Epoch 10/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 261.4734 - accuracy: 0.7064 - precision_145: 0.2655 - recall_145: 0.2674\n",
      "Epoch 11/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 985.1550 - accuracy: 0.7801 - precision_145: 0.4231 - recall_145: 0.2821\n",
      "Epoch 12/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 712.3843 - accuracy: 0.7604 - precision_145: 0.4121 - recall_145: 0.4725\n",
      "Epoch 13/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 104.9949 - accuracy: 0.7436 - precision_145: 0.3534 - recall_145: 0.3443\n",
      "Epoch 14/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 142.6541 - accuracy: 0.7699 - precision_145: 0.4118 - recall_145: 0.3590\n",
      "Epoch 15/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 407.5421 - accuracy: 0.7589 - precision_145: 0.4078 - recall_145: 0.4615\n",
      "Epoch 16/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 74.5378 - accuracy: 0.7115 - precision_145: 0.3467 - recall_145: 0.5055\n",
      "Epoch 17/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 159.2772 - accuracy: 0.7370 - precision_145: 0.4069 - recall_145: 0.6960\n",
      "Epoch 18/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 359.9703 - accuracy: 0.7400 - precision_145: 0.3480 - recall_145: 0.3480\n",
      "Epoch 19/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 72.3017 - accuracy: 0.7202 - precision_145: 0.3804 - recall_145: 0.6410\n",
      "Epoch 20/20\n",
      "137/137 [==============================] - 0s 2ms/step - loss: 82.8260 - accuracy: 0.7020 - precision_145: 0.3674 - recall_145: 0.6850\n",
      "Test size 0.50 + batch size 32 = [114.77161407470703, 0.753469705581665, 0.42500001192092896, 0.7683615684509277]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#Grafico da rede neuronal\n",
    "!pip3 install ann_visualizer\n",
    "!pip install graphviz"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-30T21:55:57.341193Z",
     "iopub.execute_input": "2022-05-30T21:55:57.341658Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ann_visualizer in c:\\users\\utilizador\\trabalhos\\pythonprojects\\lib\\site-packages (2.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\utilizador\\Trabalhos\\pythonProjects\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\utilizador\\trabalhos\\pythonprojects\\lib\\site-packages (0.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\utilizador\\Trabalhos\\pythonProjects\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "#from ann_visualizer.visualize import ann_viz;\n",
    "#ann_viz(model, title=\"VisualizaÃ§Ã£o da Rede Neuronal InsolvÃªncia\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-05-30T21:52:11.859624Z",
     "iopub.execute_input": "2022-05-30T21:52:11.860752Z",
     "iopub.status.idle": "2022-05-30T21:55:14.341386Z",
     "shell.execute_reply.started": "2022-05-30T21:52:11.860710Z",
     "shell.execute_reply": "2022-05-30T21:55:14.339580Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Carregar novo dado\n",
    "dataset = pd.read_csv('Insoltestennewcasex.csv',sep=';',header=0)\n",
    "X_new = dataset.drop('Insolvencia', axis=1)   #Colunas usadas para calcular a Insolvencia. ContÃªm as features\n",
    "\n",
    "\n",
    "#Fazer a previsÃ£o de y - InsolvÃªncia\n",
    "predictions = model.predict(X_new)\n",
    "\n",
    "if predictions[0][0] == 0:\n",
    "  print(\"Probabilidade de NÃO InsolvÃªncia, Probabilidade=%s\" % (predictions[0][0]))\n",
    "else:\n",
    "  print(\"Probabilidade de InsolvÃªncia, Probabilidade=%s\" % (predictions[0][0]))\n",
    "\n",
    "#Grafico da rede neuronal\n",
    "!pip3 install ann_visualizer\n",
    "!pip install graphviz\n",
    "\n",
    "from ann_visualizer.visualize import ann_viz;\n",
    "ann_viz(model, title=\"VisualizaÃ§Ã£o da Rede Neuronal InsolvÃªncia\")"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade de InsolvÃªncia, Probabilidade=1.0\n",
      "Requirement already satisfied: ann_visualizer in c:\\users\\utilizador\\trabalhos\\pythonprojects\\lib\\site-packages (2.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\utilizador\\Trabalhos\\pythonProjects\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\utilizador\\trabalhos\\pythonprojects\\lib\\site-packages (0.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\utilizador\\Trabalhos\\pythonProjects\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ]
  }
 ]
}